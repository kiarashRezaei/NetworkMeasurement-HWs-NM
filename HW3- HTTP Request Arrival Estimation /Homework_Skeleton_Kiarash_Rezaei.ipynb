{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgRb4mQBd2UY"
      },
      "source": [
        "#**Homework**\n",
        "\n",
        "Complete the following tasks:\n",
        "\n",
        "* Use a dataset of 21 Video Sessions\n",
        "* Recognize the Video Server(s) IP and select video traffic (***if more than one Server is found, keep the dominant flow only***)\n",
        "* Detect Video Client HTTP Requests (Uplink packets with size larger or equal to 100 Bytes)\n",
        "* Compute features to predict:\n",
        " 1.   When the next UL Request is sent by the Video Client \n",
        " 2.   How large is the response of the Server to the next UL Request\n",
        "\n",
        "**N.B.**: Below, you can find a list of useful functions for the tasks at hand (introduced during class)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "zJxa-o59dwkB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from math import sqrt\n",
        "#import tensorflow as tf\n",
        "#from tensorflow import keras\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DsJgewH_DVk"
      },
      "source": [
        "### Functions Ready-To-Use\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "-EKk7Xqfd6gI"
      },
      "outputs": [],
      "source": [
        "def filter_traffic(data, domain):\n",
        "   \n",
        "    # Look in DNS Responses for googlevideo domain\n",
        "    dns_data = data[data['Protocol']=='DNS']\n",
        "    dns = dns_data[dns_data['Info'].apply(lambda x: 'googlevideo' in x and 'response' in x)]\n",
        "    ips = dns.Address.values \n",
        "    server_names = dns.Name.values\n",
        "    \n",
        "    # Filtering on either \"Source\" or \"Destination\" IP, get the \n",
        "    # rows of the dataset that contain at least one of the selected IPs\n",
        "    downlink = data[data['Source'].apply(lambda x: x in ips)].dropna(subset=['Length']) \n",
        "    uplink = data[data['Destination'].apply(lambda x: x in ips)].dropna(subset=['Length'])\n",
        "    \n",
        "    return ips, server_names, uplink, downlink\n",
        "\n",
        "def find_dominant(uplink, downlink):\n",
        "\n",
        "  # Expressed in MB\n",
        "\n",
        "  # Order flows by cumulative DL Volume\n",
        "  flows_DL = downlink.groupby(['Source','Destination'])['Length'].sum()/(10**6)\n",
        "  print(flows_DL)\n",
        "  \n",
        "  # Get (Source,Destination) IPs of dominant flows\n",
        "  dom_id = flows_DL[flows_DL==max(flows_DL)].index[0]\n",
        "\n",
        "  # Filter traffic selecting the dominant flow\n",
        "  dom_dl = downlink[downlink['Source']==dom_id[0]]\n",
        "  dom_ul = uplink[(uplink['Destination']==dom_id[0])]\n",
        "\n",
        "  return dom_ul, dom_dl\n",
        "\n",
        "def timebased_filter(data, length=None, min_time=None, max_time=None):\n",
        "  '''\n",
        "  :param data: pd dataframe to be filtered. Must contain columns: \"Length\" and \"Time\"\n",
        "  :param length: all packets shorter than length [Bytes] will be discarded (default 0)\n",
        "  :param min_time: all packets with timestamp smaller than min_time [s] will be discarded (default 0)\n",
        "  :param max_time: all packets with timestamp larger than max_time [s] will be discarded (default 1000)\n",
        "  '''\n",
        "\n",
        "  if length is None:\n",
        "    length=0\n",
        "  if min_time is None:\n",
        "    min_time = 0\n",
        "  if max_time is None:\n",
        "    max_time = 1000\n",
        "  \n",
        "  filtered_data = data.copy().reset_index()\n",
        "  mask = (filtered_data['Length']>=length) & (filtered_data['Time']>=min_time) & (filtered_data['Time']<= max_time)\n",
        "  filtered_data = filtered_data.loc[mask[mask ==True].index]\n",
        "\n",
        "  return filtered_data\n",
        "\n",
        "def find_next(array, value):\n",
        "  '''\n",
        "  :param array: np.array, array of floats\n",
        "  :param value: float, reference value\n",
        "  :return: position of the closest element of the array greater than \"value\"\n",
        "  '''\n",
        "  delta = np.asarray(array) - value\n",
        "  idx = np.where(delta >= 0, delta, np.inf).argmin()\n",
        "\n",
        "  return idx\n",
        "\n",
        "def normalize_dataset(training_set, test_set):\n",
        "\n",
        "  mean_train = training_set.mean()\n",
        "  std_train = training_set.std()\n",
        "  norm_train = (training_set - mean_train)/std_train\n",
        "  norm_test = (test_set - mean_train)/std_train  \n",
        "\n",
        "  return norm_train, norm_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMO_nFab_IPu"
      },
      "source": [
        "### Functions to be completed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "Fi212kIMeIXr"
      },
      "outputs": [],
      "source": [
        "def features_extraction(uplink, downlink):\n",
        "  '''\n",
        "  Complete this function to extract both features and groundtruth.\n",
        "\n",
        "  NB: The features extraction process is the same as the one introduced during\n",
        "  the lecture. \n",
        "  '''\n",
        "\n",
        "  dataset = pd.DataFrame(columns=['Request_Size','Inter_RR_Time','DL_Time','DL_Vol','DL_Size','PB_Time'])\n",
        "  # ****************************************************************************\n",
        "  # Feature 1: Client Request Size\n",
        "  dataset['Request_Size'] = list(uplink.Length.values)\n",
        "\n",
        "  # ****************************************************************************\n",
        "  # Feature 2: Inter Request-Response Time\n",
        "  rr_time = []\n",
        "  response_time = []\n",
        "  for t in uplink.Time:\n",
        "    response_time.append(find_next(downlink.Time, t)) #index of next DL packet timestamp \n",
        "    rr_time.append(downlink.Time.iloc[response_time[-1]] - t)\n",
        "\n",
        "  dataset['Inter_RR_Time'] = rr_time\n",
        "\n",
        "  # ****************************************************************************\n",
        "  # Feature 3-4-5: Download Time, Download Volume, Download Size (# Packets) \n",
        "  dt = []\n",
        "  dv = []\n",
        "  ds = []\n",
        "\n",
        "  for rt1, rt2 in zip(response_time[:-1], response_time[1:]):\n",
        "\n",
        "    #Download Time\n",
        "    dt.append(downlink.Time.iloc[rt2-1] - downlink.Time.iloc[rt1])\n",
        "\n",
        "    #temp = timebased_filter_v2(downlink, 0, downlink.Time.iloc[rt1], downlink.Time.iloc[rt2-1])\n",
        "    temp = timebased_filter(downlink, 0, downlink.Time.iloc[rt1], downlink.Time.iloc[rt2-1])\n",
        "    \n",
        "    #Download Volume\n",
        "    dv.append(temp.Length.sum())\n",
        "\n",
        "    #Download Size (# Packets) \n",
        "    ds.append(temp.shape[0])\n",
        "\n",
        "  # Last Iteration data might be corrupted due to drastic interruption of capture \n",
        "  # process. If it is so, an error would occur during the features extraction.\n",
        "  # To avoid this, we skip last HTTP iteration data when an error is raised \n",
        "  # using the try-except logic below.\n",
        "  try:\n",
        "    # Consider also last HTTP iteration\n",
        "    #Download Time\n",
        "    dt.append(downlink.Time.iloc[-1] - downlink.Time.iloc[rt2])\n",
        "\n",
        "    temp = timebased_filter(downlink, 0, downlink.Time.iloc[rt2], downlink.Time.iloc[-1])\n",
        "    #Download Volume\n",
        "    dv.append(temp.Length.sum())\n",
        "\n",
        "    #Download Size (# Packets) \n",
        "    ds.append(temp.shape[0])\n",
        "  except:\n",
        "    print()\n",
        "\n",
        "  dataset['DL_Time'] = dt\n",
        "  dataset['DL_Vol'] = dv\n",
        "  dataset['DL_Size'] = ds\n",
        "\n",
        "  # ****************************************************************************\n",
        "  # Feature 5: Playback Time\n",
        "  pbt = list(uplink.Time.values)\n",
        "  dataset['PB_Time'] = pbt\n",
        "  # ****************************************************************************\n",
        "  \n",
        "  \n",
        "  # Check Features Consistency\n",
        "  dataset = dataset[(dataset > 0).all(1)]\n",
        "  dataset = dataset[dataset['DL_Time']<20]\n",
        "\n",
        "  ###############################################################\n",
        "  # TO BE COMPLETED\n",
        "\n",
        "  ### EXTRACT GROUNDTRUTH HERE\n",
        "  groundtruth = pd.DataFrame(columns=['Next_Request_Time','Next_Response_Vol'])\n",
        "  # ****************************************************************************\n",
        "\n",
        "  # Extract ground truth information\n",
        "  groundtruth = pd.DataFrame(columns=['Next_Request_Time','Next_Response_Vol'])\n",
        "\n",
        "  # GT 1: Next Request Time\n",
        "  #storing the calculated time differences between consecutive requests\n",
        "  next_req_time = uplink.Time[1:].reset_index(drop=True) - downlink.Time.iloc[response_time[:-1]].reset_index(drop=True)\n",
        "  \n",
        "  # If the time for uplink is greater than time for downlink, it means that there was no response to the last request made by the client\n",
        "  # In this case, we calculate the time difference between the last request and the end of the session and append it to the next_request_time series. \n",
        "  if len(uplink.Time) > len(downlink.Time):\n",
        "    last_res_time = downlink.Time.iloc[response_time[-1]]\n",
        "    last_ul_time = uplink.Time.iloc[-1]\n",
        "    next_req_time = next_req_time.append(pd.Series([last_ul_time - last_res_time]))\n",
        "  groundtruth['Next_Request_Time'] = next_req_time\n",
        "\n",
        "# GT 2: Next Response Volume\n",
        "  groundtruth['Next_Response_Vol'] = dataset['DL_Vol'].shift(periods=-1)\n",
        "\n",
        "  ###############################################################\n",
        "\n",
        "\n",
        "  # Check Ground Truth Consistency\n",
        "  groundtruth.dropna(inplace=True)\n",
        "\n",
        "  # Align Dataset and Groundtruth\n",
        "  intersection = set(dataset.index).intersection(set(groundtruth.index))\n",
        "  dataset = dataset.loc[intersection,:]\n",
        "  groundtruth = groundtruth.loc[intersection,:]\n",
        "\n",
        "  return dataset, groundtruth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d45P-M-v_PKm"
      },
      "source": [
        "### Write your code here - Dataset & GroundTruth Generation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "8bvmNjXvwp6y"
      },
      "outputs": [],
      "source": [
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4prKO9dxf_pB"
      },
      "outputs": [],
      "source": [
        "!unzip /content/Captures.zip\n",
        "filenames = glob.glob('/content/Captures/Capture_v2_*.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bxRLCcWwnZb",
        "outputId": "e087b264-994c-4e00-8cb1-a7e1088de502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source          Destination\n",
            "74.125.111.106  192.168.1.6     2.080363\n",
            "91.81.217.141   192.168.1.6    32.572815\n",
            "Name: Length, dtype: float64\n",
            "Source           Destination\n",
            "173.194.182.135  192.168.1.6    0.017631\n",
            "74.125.99.168    192.168.1.6    0.199115\n",
            "Name: Length, dtype: float64\n",
            "Source           Destination\n",
            "173.194.182.138  192.168.1.6    0.015734\n",
            "173.194.187.136  192.168.1.6    1.495762\n",
            "74.125.110.102   192.168.1.6    0.866399\n",
            "74.125.160.202   192.168.1.6    2.283527\n",
            "74.125.4.230     192.168.1.6    0.005583\n",
            "74.125.99.106    192.168.1.6    1.023713\n",
            "74.125.99.72     192.168.1.6    1.731761\n",
            "91.81.217.140    192.168.1.6    6.745528\n",
            "91.81.217.141    192.168.1.6    0.021178\n",
            "Name: Length, dtype: float64\n",
            "Source         Destination\n",
            "74.125.99.169  192.168.1.6    0.602666\n",
            "91.81.217.140  192.168.1.6    3.844219\n",
            "91.81.217.141  192.168.1.6    0.012511\n",
            "Name: Length, dtype: float64\n",
            "Source          Destination\n",
            "74.125.104.103  192.168.1.6     0.012088\n",
            "74.125.111.106  192.168.1.6     0.015628\n",
            "74.125.154.138  192.168.1.6     1.054021\n",
            "91.81.217.140   192.168.1.6    17.478906\n",
            "Name: Length, dtype: float64\n",
            "Source         Destination\n",
            "91.81.217.140  192.168.1.6    44.867013\n",
            "91.81.217.141  192.168.1.6    13.785031\n",
            "Name: Length, dtype: float64\n",
            "Source         Destination\n",
            "74.125.153.24  192.168.1.6    4.127591\n",
            "Name: Length, dtype: float64\n",
            "Source         Destination\n",
            "91.81.217.141  192.168.1.6    0.359344\n",
            "Name: Length, dtype: float64\n",
            "Source           Destination\n",
            "173.194.188.105  192.168.1.6    1.686488\n",
            "Name: Length, dtype: float64\n",
            "Source         Destination\n",
            "91.81.217.140  192.168.1.6    48.812378\n",
            "Name: Length, dtype: float64\n",
            "Source           Destination\n",
            "172.217.132.137  192.168.1.6    0.414788\n",
            "Name: Length, dtype: float64\n",
            "Source           Destination\n",
            "173.194.160.200  192.168.1.6    0.839776\n",
            "173.194.187.71   192.168.1.6    1.781121\n",
            "74.125.105.10    192.168.1.6    0.012088\n",
            "91.81.217.140    192.168.1.6    8.902818\n",
            "Name: Length, dtype: float64\n",
            "Source           Destination\n",
            "173.194.182.230  192.168.1.6    1.706543\n",
            "173.194.188.230  192.168.1.6    0.853296\n",
            "74.125.153.7     192.168.1.6    1.060220\n",
            "74.125.99.108    192.168.1.6    1.938626\n",
            "Name: Length, dtype: float64\n",
            "Source         Destination\n",
            "91.81.217.140  192.168.1.6    2.106974\n",
            "Name: Length, dtype: float64\n",
            "Source         Destination\n",
            "91.81.217.141  192.168.1.6    9.993622\n",
            "Name: Length, dtype: float64\n",
            "Source           Destination\n",
            "173.194.188.136  192.168.1.6    0.158705\n",
            "74.125.111.102   192.168.1.6    1.924227\n",
            "74.125.153.11    192.168.1.6    0.008252\n",
            "74.125.99.166    192.168.1.6    1.296750\n",
            "74.125.99.168    192.168.1.6    0.652067\n",
            "Name: Length, dtype: float64\n",
            "Source         Destination\n",
            "74.125.160.38  192.168.1.6    0.008204\n",
            "74.125.99.168  192.168.1.6    0.410873\n",
            "74.125.99.170  192.168.1.6    2.693258\n",
            "Name: Length, dtype: float64\n",
            "Source          Destination\n",
            "74.125.111.105  192.168.1.6    7.992543\n",
            "74.125.99.105   192.168.1.6    0.009947\n",
            "91.81.217.140   192.168.1.6    2.965944\n",
            "Name: Length, dtype: float64\n",
            "Source           Destination\n",
            "173.194.160.219  192.168.1.6    0.008240\n",
            "173.194.188.72   192.168.1.6    1.974872\n",
            "74.125.153.59    192.168.1.6    0.012162\n",
            "74.125.99.108    192.168.1.6    0.015762\n",
            "Name: Length, dtype: float64\n",
            "Source         Destination\n",
            "209.85.226.38  192.168.1.6    0.549426\n",
            "74.125.162.39  192.168.1.6    0.015674\n",
            "74.125.162.40  192.168.1.6    2.380683\n",
            "74.125.99.170  192.168.1.6    0.015766\n",
            "Name: Length, dtype: float64\n",
            "Source         Destination\n",
            "74.125.99.137  192.168.1.6    1.441036\n",
            "Name: Length, dtype: float64\n",
            "Source          Destination\n",
            "74.125.163.138  192.168.1.6    0.008266\n",
            "74.125.99.91    192.168.1.6    0.008056\n",
            "Name: Length, dtype: float64\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# Create empty lists to hold the datasets and groundtruths\n",
        "dataset_list = []\n",
        "groundtruth_list = []\n",
        "# timebased_filter function parameters\n",
        "playback_start = 2\n",
        "playback_end = 180\n",
        "min_ul_size = 100\n",
        "min_dl_size = 50\n",
        "\n",
        "# Iterate over each filename in the list of filenames\n",
        "for filename in filenames:\n",
        "\n",
        "    # Read the CSV file into a pandas DataFrame\n",
        "    df = pd.read_csv(filename, sep=',', encoding='latin-1')\n",
        "\n",
        "    # Filter the DataFrame for traffic related to Google Video\n",
        "    _,__,ul, dl = filter_traffic(df, 'googlevideo')\n",
        "\n",
        "    # Find the dominant upstream and downstream flows for the filtered DataFrame\n",
        "    # TCP flows have been filtered since are not relevant to googlevideo(do not correspond to actual data transferred)\n",
        "    dom_ul, dom_dl = find_dominant(ul, dl)\n",
        "    dom_ul = timebased_filter(dom_ul, min_ul_size, playback_start, playback_end)\n",
        "    dom_ul = dom_ul[dom_ul['Protocol'] != 'TCP']\n",
        "    dom_dl = timebased_filter(dom_dl, min_dl_size, playback_start, playback_end)\n",
        "    \n",
        "    # Extract features from the dominant upstream and downstream flows\n",
        "    ds, gt = features_extraction(dom_ul, dom_dl)\n",
        "\n",
        "    # Append the extracted dataset and ground truth to the respective lists\n",
        "    dataset_list.append(ds)\n",
        "    groundtruth_list.append(gt)\n",
        "\n",
        "# Concatenate all dataset_list into a single DataFrame\n",
        "dataset = pd.concat(dataset_list, ignore_index=True)\n",
        "\n",
        "# Concatenate all ground truths into a single DataFrame\n",
        "groundtruth = pd.concat(groundtruth_list, ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "UtJEl1V83lNn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "1adad848-155f-4ebb-8c6e-6f832dc53c3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Request_Size  Inter_RR_Time   DL_Time    DL_Vol  DL_Size    PB_Time\n",
              "0         644.0       0.010329  0.192246  500058.0    333.0   4.152173\n",
              "1         627.0       0.003737  0.496860  494034.0    329.0   6.173422\n",
              "2         645.0       0.003889  0.049695  113040.0     76.0   8.249755\n",
              "3         645.0       0.004516  2.248406  592749.0    396.0  10.257419\n",
              "4         646.0       0.010285  0.985976  146733.0     99.0  13.260990\n",
              "5         622.0       0.003852  0.204691  218132.0    146.0  14.348942\n",
              "6         647.0       0.010206  0.191562  501604.0    334.0  16.269078\n",
              "7         647.0       0.012687  0.025851   77958.0     53.0  18.279838\n",
              "8         647.0       0.003656  0.039299   97964.0     66.0  20.957692\n",
              "9         545.0       0.009862  0.191857  498576.0    332.0  21.845354"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-663e9048-bda5-44cf-bde7-b500a68c749c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Request_Size</th>\n",
              "      <th>Inter_RR_Time</th>\n",
              "      <th>DL_Time</th>\n",
              "      <th>DL_Vol</th>\n",
              "      <th>DL_Size</th>\n",
              "      <th>PB_Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>644.0</td>\n",
              "      <td>0.010329</td>\n",
              "      <td>0.192246</td>\n",
              "      <td>500058.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>4.152173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>627.0</td>\n",
              "      <td>0.003737</td>\n",
              "      <td>0.496860</td>\n",
              "      <td>494034.0</td>\n",
              "      <td>329.0</td>\n",
              "      <td>6.173422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>645.0</td>\n",
              "      <td>0.003889</td>\n",
              "      <td>0.049695</td>\n",
              "      <td>113040.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>8.249755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>645.0</td>\n",
              "      <td>0.004516</td>\n",
              "      <td>2.248406</td>\n",
              "      <td>592749.0</td>\n",
              "      <td>396.0</td>\n",
              "      <td>10.257419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>646.0</td>\n",
              "      <td>0.010285</td>\n",
              "      <td>0.985976</td>\n",
              "      <td>146733.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>13.260990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>622.0</td>\n",
              "      <td>0.003852</td>\n",
              "      <td>0.204691</td>\n",
              "      <td>218132.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>14.348942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>647.0</td>\n",
              "      <td>0.010206</td>\n",
              "      <td>0.191562</td>\n",
              "      <td>501604.0</td>\n",
              "      <td>334.0</td>\n",
              "      <td>16.269078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>647.0</td>\n",
              "      <td>0.012687</td>\n",
              "      <td>0.025851</td>\n",
              "      <td>77958.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>18.279838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>647.0</td>\n",
              "      <td>0.003656</td>\n",
              "      <td>0.039299</td>\n",
              "      <td>97964.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>20.957692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>545.0</td>\n",
              "      <td>0.009862</td>\n",
              "      <td>0.191857</td>\n",
              "      <td>498576.0</td>\n",
              "      <td>332.0</td>\n",
              "      <td>21.845354</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-663e9048-bda5-44cf-bde7-b500a68c749c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-663e9048-bda5-44cf-bde7-b500a68c749c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-663e9048-bda5-44cf-bde7-b500a68c749c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ],
      "source": [
        "dataset.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groundtruth.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "uviQAzi972Ky",
        "outputId": "ea4fe0fa-bf0e-4f97-e3b1-f544922faaaa"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Next_Request_Time  Next_Response_Vol\n",
              "0           2.010920           494034.0\n",
              "1           2.072596           113040.0\n",
              "2           2.003775           592749.0\n",
              "3           2.999055           146733.0\n",
              "4           1.077667           218132.0\n",
              "5           1.916284           501604.0\n",
              "6           2.000554            77958.0\n",
              "7           2.665167            97964.0\n",
              "8           0.884006           498576.0\n",
              "9           1.781129           500074.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b1f68810-0817-41bb-97cd-65325c2e1ff6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Next_Request_Time</th>\n",
              "      <th>Next_Response_Vol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.010920</td>\n",
              "      <td>494034.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.072596</td>\n",
              "      <td>113040.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.003775</td>\n",
              "      <td>592749.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.999055</td>\n",
              "      <td>146733.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.077667</td>\n",
              "      <td>218132.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.916284</td>\n",
              "      <td>501604.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2.000554</td>\n",
              "      <td>77958.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2.665167</td>\n",
              "      <td>97964.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.884006</td>\n",
              "      <td>498576.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.781129</td>\n",
              "      <td>500074.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1f68810-0817-41bb-97cd-65325c2e1ff6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b1f68810-0817-41bb-97cd-65325c2e1ff6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b1f68810-0817-41bb-97cd-65325c2e1ff6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regression:** I used **Random forest**, **Support Vector Regression** and a simple **Multi Layer Perceptron** for this task. To conclude, results obtaind by RF is closer to the Prof's result.\n",
        "Note: I trained RF regressors for different number of estimators([100,150,200,250,300]) but results have not changed significantly."
      ],
      "metadata": {
        "id": "ZXQXUfRehR5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define range of the number of estimator values to try\n",
        "estimator_range = range(100, 301, 50)\n",
        "\n",
        "# Initialize lists to store results\n",
        "rf_time_rmse = []\n",
        "rf_vol_rmse = []\n",
        "\n",
        "kf = KFold(n_splits=10)\n",
        "\n",
        "for train_idx, test_idx in kf.split(dataset):\n",
        "    # Split data into training and test sets\n",
        "    X_train, X_test = dataset.iloc[train_idx], dataset.iloc[test_idx]\n",
        "    Y_time_train, Y_time_test = groundtruth['Next_Request_Time'].iloc[train_idx], groundtruth['Next_Request_Time'].iloc[test_idx]\n",
        "    Y_vol_train, Y_vol_test = groundtruth['Next_Response_Vol'].iloc[train_idx], groundtruth['Next_Response_Vol'].iloc[test_idx]\n",
        "\n",
        "    # Normalize datasets\n",
        "    norm_train, norm_test = normalize_dataset(X_train, X_test)\n",
        "\n",
        "    # Train random forest regressor for each estimator value\n",
        "    time_errors = []\n",
        "    vol_errors = []\n",
        "    for n in estimator_range:\n",
        "        rf_time = RandomForestRegressor(n_estimators=n, random_state=3).fit(norm_train, Y_time_train)\n",
        "        rf_vol = RandomForestRegressor(n_estimators=n, random_state=3).fit(norm_train, Y_vol_train)\n",
        "\n",
        "        # Make predictions\n",
        "        pred_time = rf_time.predict(norm_test)\n",
        "        pred_vol = rf_vol.predict(norm_test)\n",
        "\n",
        "        # Collect results\n",
        "        time_errors.append(sqrt(metrics.mean_squared_error(Y_time_test, pred_time)))\n",
        "        vol_errors.append(sqrt(metrics.mean_squared_error(Y_vol_test, pred_vol)))\n",
        "\n",
        "    # Store results for this fold\n",
        "    rf_time_rmse.append(time_errors)\n",
        "    rf_vol_rmse.append(vol_errors)\n"
      ],
      "metadata": {
        "id": "o389PfYb7JsM"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the result\n",
        "print(\"--------------------Random Forest---------------\\n\")\n",
        "print(\"Estimation of the arrival time of next HTTP Request:\\n\")\n",
        "print(\"RMSE = {} [s] (std = {})\\n\".format(np.mean(rf_time_rmse), np.std(rf_time_rmse)))\n",
        "print(\"------------------------\\n\")\n",
        "print(\"Prediction of the next burst size from the server:\\n\")\n",
        "print(\"RMSE = {} [KB] (std = {})\\n\".format((np.mean(rf_vol_rmse))/1000, (np.std(rf_vol_rmse))/1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vgub0n_7vNj",
        "outputId": "e52de863-6f35-4f9e-a14a-7f7ed6b86e13"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------Random Forest---------------\n",
            "\n",
            "Estimation of the arrival time of next HTTP Request:\n",
            "\n",
            "RMSE = 5.823775997199808 [s] (std = 2.214806995876364)\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prediction of the next burst size from the server:\n",
            "\n",
            "RMSE = 382.1455748785304 [KB] (std = 117.57161316473793)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to store RMSE(time and vol) for each fold\n",
        "rf_time_rmse = []\n",
        "rf_vol_rmse = []\n",
        "\n",
        "kf = KFold(n_splits=10)\n",
        "\n",
        "for train_idx, test_idx in kf.split(dataset):\n",
        "    # Split data into training and test sets\n",
        "    X_train, X_test = dataset.iloc[train_idx], dataset.iloc[test_idx]\n",
        "    Y_time_train, Y_time_test = groundtruth['Next_Request_Time'].iloc[train_idx], groundtruth['Next_Request_Time'].iloc[test_idx]\n",
        "    Y_vol_train, Y_vol_test = groundtruth['Next_Response_Vol'].iloc[train_idx], groundtruth['Next_Response_Vol'].iloc[test_idx]\n",
        "\n",
        "    # Normalize datasets\n",
        "    norm_train, norm_test = normalize_dataset(X_train, X_test)\n",
        "\n",
        "    # Train random forest regressor\n",
        "    rf_time = RandomForestRegressor(random_state=3).fit(norm_train, Y_time_train)\n",
        "    rf_vol = RandomForestRegressor(random_state=3).fit(norm_train, Y_vol_train)\n",
        "\n",
        "    # Make predictions\n",
        "    pred_time = rf_time.predict(norm_test)\n",
        "    pred_vol = rf_vol.predict(norm_test)\n",
        "\n",
        "    # Collect results\n",
        "    rf_time_rmse.append(sqrt(metrics.mean_squared_error(Y_time_test, pred_time)))\n",
        "    rf_vol_rmse.append(sqrt(metrics.mean_squared_error(Y_vol_test, pred_vol)))"
      ],
      "metadata": {
        "id": "bgVmkpGXcft9"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the result\n",
        "print(\"--------------------Random Forest---------------\\n\")\n",
        "print(\"Estimation of the arrival time of next HTTP Request:\\n\")\n",
        "print(\"RMSE = {} [s] (std = {})\\n\".format(np.mean(rf_time_rmse), np.std(rf_time_rmse)))\n",
        "print(\"------------------------\\n\")\n",
        "print(\"Prediction of the next burst size from the server:\\n\")\n",
        "print(\"RMSE = {} [KB] (std = {})\\n\".format((np.mean(rf_vol_rmse))/1000, (np.std(rf_vol_rmse))/1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IG7uEBUeK62",
        "outputId": "f94440a6-e98d-4065-8448-fa8e963283a3"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------Random Forest---------------\n",
            "\n",
            "Estimation of the arrival time of next HTTP Request:\n",
            "\n",
            "RMSE = 5.80829323358744 [s] (std = 2.240064135066082)\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prediction of the next burst size from the server:\n",
            "\n",
            "RMSE = 381.4835256059127 [KB] (std = 118.5245632030567)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to store RMSE(time and vol) for each fold\n",
        "svr_time_rmse = []\n",
        "svr_vol_rmse = []\n",
        "\n",
        "kf = KFold(n_splits=10)\n",
        "\n",
        "for train_idx, test_idx in kf.split(dataset):\n",
        "    # Split data into training and test sets\n",
        "    X_train, X_test = dataset.iloc[train_idx], dataset.iloc[test_idx]\n",
        "    Y_time_train, Y_time_test = groundtruth['Next_Request_Time'].iloc[train_idx], groundtruth['Next_Request_Time'].iloc[test_idx]\n",
        "    Y_vol_train, Y_vol_test = groundtruth['Next_Response_Vol'].iloc[train_idx], groundtruth['Next_Response_Vol'].iloc[test_idx]\n",
        "\n",
        "    # Normalize datasets\n",
        "    norm_train, norm_test = normalize_dataset(X_train, X_test)\n",
        "\n",
        "    # Train SVR regressor\n",
        "    svr_time = SVR(kernel='rbf', C=1, gamma='scale').fit(norm_train, Y_time_train)\n",
        "    svr_vol = SVR(kernel='rbf', C=1, gamma='scale').fit(norm_train, Y_vol_train)\n",
        "\n",
        "    # Make predictions\n",
        "    pred_time = svr_time.predict(norm_test)\n",
        "    pred_vol = svr_vol.predict(norm_test)\n",
        "\n",
        "    # Collect results\n",
        "    svr_time_rmse.append(sqrt(metrics.mean_squared_error(Y_time_test, pred_time)))\n",
        "    svr_vol_rmse.append(sqrt(metrics.mean_squared_error(Y_vol_test, pred_vol)))\n"
      ],
      "metadata": {
        "id": "F6v3-n0mfaEb"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the result\n",
        "print(\"--------------------Support Vector Regression---------------\\n\")\n",
        "print(\"Estimation of the arrival time of next HTTP Request:\\n\")\n",
        "print(\"RMSE = {} [s] (std = {})\\n\".format(np.mean(svr_time_rmse), np.std(svr_time_rmse)))\n",
        "print(\"------------------------\\n\")\n",
        "print(\"Prediction of the next burst size from the server:\\n\")\n",
        "print(\"RMSE = {} [KB] (std = {})\\n\".format((np.mean(svr_vol_rmse))/1000, (np.std(svr_vol_rmse))/1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw6kBeYPfpjL",
        "outputId": "f944c6bb-9bc0-4dc2-b130-cc06cdfbc419"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------Support Vector Regression---------------\n",
            "\n",
            "Estimation of the arrival time of next HTTP Request:\n",
            "\n",
            "RMSE = 5.943733174287085 [s] (std = 2.9495968680565476)\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prediction of the next burst size from the server:\n",
            "\n",
            "RMSE = 467.007124359698 [KB] (std = 232.1408659420704)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to store RMSE(time and vol) for each fold\n",
        "mlp_time_rmse = []\n",
        "mlp_vol_rmse = []\n",
        "\n",
        "kf = KFold(n_splits=10)\n",
        "\n",
        "for train_idx, test_idx in kf.split(dataset):\n",
        "    # Split data into training and test sets\n",
        "    X_train, X_test = dataset.iloc[train_idx], dataset.iloc[test_idx]\n",
        "    Y_time_train, Y_time_test = groundtruth['Next_Request_Time'].iloc[train_idx], groundtruth['Next_Request_Time'].iloc[test_idx]\n",
        "    Y_vol_train, Y_vol_test = groundtruth['Next_Response_Vol'].iloc[train_idx], groundtruth['Next_Response_Vol'].iloc[test_idx]\n",
        "\n",
        "    # Normalize datasets\n",
        "    norm_train, norm_test = normalize_dataset(X_train, X_test)\n",
        "\n",
        "    # Train MLP regressor\n",
        "    mlp_time = MLPRegressor(hidden_layer_sizes=(100, 50), activation='tanh', solver='adam', random_state=3).fit(norm_train, Y_time_train)\n",
        "    mlp_vol = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=3).fit(norm_train, Y_vol_train)\n",
        "\n",
        "    # Make predictions\n",
        "    pred_time = mlp_time.predict(norm_test)\n",
        "    pred_vol = mlp_vol.predict(norm_test)\n",
        "\n",
        "    # Collect results\n",
        "    mlp_time_rmse.append(sqrt(metrics.mean_squared_error(Y_time_test, pred_time)))\n",
        "    mlp_vol_rmse.append(sqrt(metrics.mean_squared_error(Y_vol_test, pred_vol)))\n"
      ],
      "metadata": {
        "id": "AI6Otu0VRUtw"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the result\n",
        "print(\"--------------------Multi Layer Perceptron---------------\\n\")\n",
        "print(\"Estimation of the arrival time of next HTTP Request:\\n\")\n",
        "print(\"RMSE = {} [s] (std = {})\\n\".format(np.mean(mlp_time_rmse), np.std(mlp_time_rmse)))\n",
        "print(\"------------------------\\n\")\n",
        "print(\"Prediction of the next burst size from the server:\\n\")\n",
        "print(\"RMSE = {} [KB] (std = {})\\n\".format((np.mean(mlp_vol_rmse))/1000, (np.std(mlp_vol_rmse))/1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxgSyRfwkPX1",
        "outputId": "f16bbe3b-9fff-4f3f-adc9-62a21132c581"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------Multi Layer Perceptron---------------\n",
            "\n",
            "Estimation of the arrival time of next HTTP Request:\n",
            "\n",
            "RMSE = 6.42558141754733 [s] (std = 2.1822942631936737)\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prediction of the next burst size from the server:\n",
            "\n",
            "RMSE = 652.5453455380982 [KB] (std = 320.07008298107087)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "66JOFCK36pWJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}